name: NetsPresso QA Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 9 * * *'
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        else
          pip install torch torchvision netspresso
        fi
        pip install pytest pytest-html pytest-json-report
    
    - name: Create directories
      run: |
        mkdir -p tests
        mkdir -p results/test_results
        mkdir -p results/reports
    
    - name: Create basic test file
      run: |
        cat > tests/test_basic.py << 'EOF'
        import pytest
        import os
        import sys
        from datetime import datetime

        class TestBasicFunctionality:
            def test_python_version(self):
                """Python ë²„ì „ í™•ì¸"""
                assert sys.version_info >= (3, 8)
                print(f"âœ… Python ë²„ì „: {sys.version}")
            
            def test_api_key_exists(self):
                """API í‚¤ ì¡´ì¬ í™•ì¸"""
                api_key = os.environ.get('NETSPRESSO_API_KEY')
                if api_key:
                    assert len(api_key) > 10
                    print("âœ… API í‚¤ í™•ì¸ë¨")
                else:
                    print("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
            def test_torch_import(self):
                """PyTorch import í…ŒìŠ¤íŠ¸"""
                try:
                    import torch
                    print(f"âœ… PyTorch ë²„ì „: {torch.__version__}")
                except ImportError:
                    pytest.skip("PyTorch ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            
            def test_netspresso_import(self):
                """NetsPresso import í…ŒìŠ¤íŠ¸"""
                try:
                    import netspresso
                    print("âœ… NetsPresso ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ")
                except ImportError:
                    print("âš ï¸ NetsPresso ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ")
            
            def test_file_system(self):
                """íŒŒì¼ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
                import json
                
                # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
                test_result = {
                    "test_name": "basic_file_system_test",
                    "timestamp": datetime.now().isoformat(),
                    "success": True,
                    "environment": "github_actions"
                }
                
                os.makedirs('results/test_results', exist_ok=True)
                filename = f'results/test_results/basic_test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(test_result, f, ensure_ascii=False, indent=2)
                
                assert os.path.exists(filename)
                print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥: {filename}")
        EOF
    
    - name: Run basic tests
      env:
        NETSPRESSO_API_KEY: ${{ secrets.NETSPRESSO_API_KEY }}
      run: |
        echo "ğŸ§ª ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
        python -m pytest tests/test_basic.py -v --json-report --json-report-file=results/pytest_report.json --html=results/pytest_report.html --self-contained-html
      continue-on-error: true
    
    - name: Run additional NetsPresso tests
      env:
        NETSPRESSO_API_KEY: ${{ secrets.NETSPRESSO_API_KEY }}
      run: |
        echo "ğŸ” ì¶”ê°€ NetsPresso í…ŒìŠ¤íŠ¸..."
        
        # ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆìœ¼ë©´ ì‹¤í–‰
        if [ -f "src/netspresso_client.py" ]; then
          echo "NetsPresso í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰"
          timeout 300 python src/netspresso_client.py || echo "í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰ ì™„ë£Œ (íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ì˜¤ë¥˜)"
        fi
        
        if [ -f "scripts/test_result_saver.py" ]; then
          echo "í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³€í™˜"
          python scripts/test_result_saver.py || echo "ê²°ê³¼ ë³€í™˜ ì™„ë£Œ"
        fi
      continue-on-error: true
    
    - name: Generate QA report
      run: |
        echo "ğŸ“Š QA ë¦¬í¬íŠ¸ ìƒì„±..."
        
        python3 << 'EOF'
        import json
        import os
        from datetime import datetime

        report = f"""# NetsPresso QA í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸

        **ìƒì„± ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        **ì‹¤í–‰ í™˜ê²½**: GitHub Actions
        **ì›Œí¬í”Œë¡œìš° ID**: ${{ github.run_id }}

        ## ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½

        """

        # pytest ê²°ê³¼ ì½ê¸°
        pytest_file = 'results/pytest_report.json'
        if os.path.exists(pytest_file):
            try:
                with open(pytest_file, 'r') as f:
                    pytest_data = json.load(f)
                
                summary = pytest_data.get('summary', {})
                total = summary.get('total', 0)
                passed = summary.get('passed', 0)
                failed = summary.get('failed', 0)
                
                report += f"""| í•­ëª© | ê°’ |
        |------|----:|
        | ì „ì²´ í…ŒìŠ¤íŠ¸ | {total}ê°œ |
        | ì„±ê³µ | {passed}ê°œ |
        | ì‹¤íŒ¨ | {failed}ê°œ |
        """
                
                if total > 0:
                    success_rate = (passed / total) * 100
                    report += f"| ì„±ê³µë¥  | {success_rate:.1f}% |\n"
                
            except Exception as e:
                report += f"pytest ê²°ê³¼ ë¡œë“œ ì˜¤ë¥˜: {e}\n"
        else:
            report += "pytest ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"

        report += """

        ## ğŸ¯ QA ê²°ë¡ 

        - GitHub Actionsì—ì„œ ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì™„ë£Œ
        - ê¸°ë³¸ ê¸°ëŠ¥ ê²€ì¦ ìˆ˜í–‰
        - ì§€ì†ì ì¸ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ í™œì„±í™”

        ## ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„

        1. ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ì›ì¸ ë¶„ì„
        2. API í‚¤ ë° í™˜ê²½ ì„¤ì • ê²€í†   
        3. ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ê°œë°œ

        ---
        *ì´ ë¦¬í¬íŠ¸ëŠ” GitHub Actionsì—ì„œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
        """

        # ë¦¬í¬íŠ¸ ì €ì¥
        os.makedirs('results', exist_ok=True)
        with open('results/qa_summary_report.md', 'w', encoding='utf-8') as f:
            f.write(report)

        print('âœ… QA ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ')
        EOF
    
    - name: Create test summary
      if: always()
      run: |
        echo "ğŸ“ í…ŒìŠ¤íŠ¸ ìš”ì•½ ìƒì„±..."
        {
          echo "=== NetsPresso QA í…ŒìŠ¤íŠ¸ ê²°ê³¼ ==="
          echo "ì‹¤í–‰ ì‹œê°„: $(date)"
          echo "ì›Œí¬í”Œë¡œìš° ID: ${{ github.run_id }}"
          echo "íŠ¸ë¦¬ê±°: ${{ github.event_name }}"
          echo ""
          echo "=== ìƒì„±ëœ íŒŒì¼ ==="
          find results/ -type f 2>/dev/null || echo "ê²°ê³¼ íŒŒì¼ ì—†ìŒ"
          echo ""
          echo "=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ==="
        } > test_summary.txt
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ github.run_number }}
        path: |
          test_summary.txt
          results/
        retention-days: 30
    
    - name: Display results summary
      if: always()
      run: |
        echo "ğŸ‰ GitHub Actions í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
        echo ""
        echo "ğŸ“Š ê²°ê³¼ í™•ì¸ ë°©ë²•:"
        echo "1. ìœ„ ë‹¨ê³„ì˜ 'Upload results' ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ"
        echo "2. results/ í´ë” ë‚´ qa_summary_report.md í™•ì¸"
        echo "3. pytest_report.htmlë¡œ ìƒì„¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸"
        echo ""
        echo "ğŸ”— ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"